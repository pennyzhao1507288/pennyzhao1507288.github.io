<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Natural Language Processing Language Models | We are the Champions</title><meta name="author" content="Penny Zhao"><meta name="copyright" content="Penny Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="🏂Computer version 开始观看  🥕 Natural Language Processing Language Models  ⛺自然语言处理（NLP）与语言模型  🪐处理自然语言的能力  人与其他物种的区别：  人类能够通过自然语言进行交流和获取信息，这是区分人类与其他物种的重要特征。   与图灵测试的关系：  自然语言处理是图灵测试的基础，图灵测试评估机器是否能够表现出与">
<meta property="og:type" content="article">
<meta property="og:title" content="Natural Language Processing Language Models">
<meta property="og:url" content="https://pennyzhao1507288.github.io/posts/c5806683/index.html">
<meta property="og:site_name" content="We are the Champions">
<meta property="og:description" content="🏂Computer version 开始观看  🥕 Natural Language Processing Language Models  ⛺自然语言处理（NLP）与语言模型  🪐处理自然语言的能力  人与其他物种的区别：  人类能够通过自然语言进行交流和获取信息，这是区分人类与其他物种的重要特征。   与图灵测试的关系：  自然语言处理是图灵测试的基础，图灵测试评估机器是否能够表现出与">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pennyzhao1507288.github.io/cover_image/24011_week9_cover2.jpg">
<meta property="article:published_time" content="2024-11-24T22:17:19.000Z">
<meta property="article:modified_time" content="2024-11-24T22:58:19.830Z">
<meta property="article:author" content="Penny Zhao">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pennyzhao1507288.github.io/cover_image/24011_week9_cover2.jpg"><link rel="shortcut icon" href="/img/profile.jpg"><link rel="canonical" href="https://pennyzhao1507288.github.io/posts/c5806683/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="giU_VQBe1Zf22KsD7tRopSheFkjqhH-YcrI8GOuM5Vo"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Natural Language Processing Language Models',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/cursor.css"><link rel="stylesheet" href="/css/background.css"><link rel="stylesheet" href="/css/font.css"><meta name="google-site-verification" content="giU_VQBe1Zf22KsD7tRopSheFkjqhH-YcrI8GOuM5Vo" /><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background-image: url(url(https://i.loli.net/2019/09/09/5oDRkWVKctx2b6A.png));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/profile.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/video/"><i class="fa-fw fas fa-video"></i><span> 视频集</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/cover_image/24011_week9_cover2.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">We are the Champions</span></a><a class="nav-page-title" href="/"><span class="site-name">Natural Language Processing Language Models</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/video/"><i class="fa-fw fas fa-video"></i><span> 视频集</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Natural Language Processing Language Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-24T22:17:19.000Z" title="发表于 2024-11-25 06:17:19">2024-11-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-11-24T22:58:19.830Z" title="更新于 2024-11-25 06:58:19">2024-11-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Computer-science/">Computer science</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="-swig0-"><a class="markdownIt-Anchor" href="#-swig0-"></a> 🏂<span class='p blue'>Computer version</span></h1>
<div class="progress"><div class="progress-bar-animated progress-bar progress-bar-striped bg-gray"  style="width: 1%" aria-valuenow="1" aria-valuemin="0" aria-valuemax="100"><p>开始观看</p></div></div>
<h2 id="-swig2-"><a class="markdownIt-Anchor" href="#-swig2-"></a> 🥕 <emp>Natural Language Processing Language Models</emp></h2>
<h3 id="-swig3-"><a class="markdownIt-Anchor" href="#-swig3-"></a> ⛺<wavy>自然语言处理（NLP）与语言模型</wavy></h3>
<h4 id="-swig4-"><a class="markdownIt-Anchor" href="#-swig4-"></a> 🪐<u>处理自然语言的能力</u></h4>
<ol>
<li><strong>人与其他物种的区别</strong>：
<ul>
<li>人类能够通过自然语言进行交流和获取信息，这是区分人类与其他物种的重要特征。</li>
</ul>
</li>
<li><strong>与图灵测试的关系</strong>：
<ul>
<li>自然语言处理是<strong>图灵测试</strong>的基础，图灵测试评估机器是否能够表现出与人类智能行为相当的能力。</li>
</ul>
</li>
<li><strong>为什么需要这种能力？</strong>
<ul>
<li>机器需要<img src="https://github.com/pennyzhao1507288/img_store/raw/main/24011%20intro%20AI/week9/week9_6.png" alt="Image" style="zoom:70%;" />
<ul>
<li><strong>获取信息</strong>：例如，从文章中提取有用的数据。</li>
<li><strong>进行交流</strong>：例如，聊天机器人用自然对话回答你的问题。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig5-"><a class="markdownIt-Anchor" href="#-swig5-"></a> 🪐<u>通过NLP实现知识获取</u></h4>
<ol>
<li><strong>理解含糊的语言</strong>：
<ul>
<li>自然语言经常模糊且依赖上下文，机器需要像人类一样理解这些复杂性，才能准确处理语言。</li>
</ul>
</li>
<li><strong>信息检索任务</strong>：
<ul>
<li><strong>文本分类</strong>：比如将电子邮件分类为垃圾邮件或正常邮件。</li>
<li><strong>信息检索</strong>：搜索引擎根据你的问题找到最相关的网页。</li>
<li><strong>信息抽取</strong>：从新闻中提取关键信息，例如人名、地点和日期。</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig6-"><a class="markdownIt-Anchor" href="#-swig6-"></a> 🪐<u>语言模型的作用</u></h4>
<ol>
<li><strong>什么是语言模型？</strong>
<ul>
<li>语言模型预测句子或上下文中<strong>单词的概率分布</strong>。</li>
<li>例子：在句子 “The cat sat on the ___” 中，语言模型可能预测下一个单词是 “mat”，并赋予其较高的概率。</li>
</ul>
</li>
<li><strong>语言模型的用途</strong>：
<ul>
<li>它们在以下任务中起关键作用：
<ul>
<li><strong>生成连贯的文本</strong>（如输入法的自动补全功能）。</li>
<li><strong>理解上下文</strong>（如翻译或文本摘要）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<blockquote>
<p>🌐语言模型的实际生活例子</p>
<p>想象你在手机上输入：</p>
<ul>
<li>当你打出 “我感觉” 后，手机可能会建议 “开心” 或 “兴奋”。</li>
<li>这些建议来源于语言模型，它基于成千上万句子中学到的语言模式。</li>
</ul>
</blockquote>
<h4 id="-swig7-"><a class="markdownIt-Anchor" href="#-swig7-"></a> 🪐<u>语言的特性</u></h4>
<ol>
<li>
<p><strong>无限的可能性</strong>：</p>
<ul>
<li>语言中可以构造出无限多的句子（字符串），因此无法穷举所有可能。</li>
<li>这些可能性由规则定义，即<strong>语法（grammar）</strong>。</li>
</ul>
</li>
<li>
<p><strong>自然语言的挑战</strong>：</p>
<ul>
<li><strong>不确定性（Uncertainty）</strong>：
<ul>
<li>某些句子是否属于语法规则的范围是有争议的。例如，句子 “Not to be invited is sad” 是否符合英语语法，可能存在不同意见。</li>
</ul>
</li>
<li><strong>歧义性（Ambiguity）</strong>：
<ul>
<li>自然语言句子常常有多种含义。例如，句子 “He saw a man with a telescope” 可以有两种解释：
<ol>
<li>他用望远镜看到了一个人。</li>
<li>他看到了一个带望远镜的人。</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig8-"><a class="markdownIt-Anchor" href="#-swig8-"></a> 🪐<u>语言模型的概率分布</u></h4>
<p>由于自然语言具有不确定性和歧义性，我们使用**概率分布（probability distributions）**来处理这些问题。</p>
<ol>
<li>
<p><strong>处理不确定性</strong>：</p>
<ul>
<li>对于句子 “Not to be invited is sad”，语言模型会计算它在英语中的出现概率，以此评估它的合理性。</li>
</ul>
</li>
<li>
<p><strong>处理歧义性</strong>：</p>
<ul>
<li>对于句子 “He saw a man with a telescope”，语言模型会为每种可能的含义分配概率。</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig9-"><a class="markdownIt-Anchor" href="#-swig9-"></a> 🪐<u>自然语言的复杂性</u></h4>
<ol>
<li>
<p><strong>规模大</strong>：</p>
<ul>
<li>自然语言词汇量庞大，句子结构复杂，覆盖了大量的上下文和语境。</li>
</ul>
</li>
<li>
<p><strong>动态变化</strong>：</p>
<ul>
<li>自然语言是不断演化的，新词、新表达层出不穷。</li>
</ul>
</li>
</ol>
<p>因此，语言模型只能对语言做**近似（approximation）**处理。</p>
<hr />
<p>📚假设你输入一段文字：</p>
<ul>
<li>输入：“The weather is”</li>
<li>模型可能预测：
<ul>
<li>“nice”（概率 60%）</li>
<li>“bad”（概率 30%）</li>
<li>“cold”（概率 10%）</li>
</ul>
</li>
</ul>
<p>语言模型根据大量文本数据学习的概率分布，选择最可能的输出。这种机制使得语言模型可以完成从自动补全到翻译、生成文章等多种任务。</p>
<hr />
<h3 id="-swig10-"><a class="markdownIt-Anchor" href="#-swig10-"></a> ⛺<wavy>N-gram Character Models</wavy></h3>
<h4 id="-swig11-"><a class="markdownIt-Anchor" href="#-swig11-"></a> 🪐<u>什么是N-gram模型？</u></h4>
<p>N-gram是指一段连续的字符或单词序列，用于预测自然语言中出现字符或单词的概率分布。N-gram模型常被用来简化语言建模问题。</p>
<ol>
<li>
<p><strong>核心概念</strong>：</p>
<ul>
<li><strong>N-gram</strong> 是一个长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> 的字符或单词序列。例如：
<ul>
<li>1-gram（unigram）：单个字符或单词。</li>
<li>2-gram（bigram）：两个连续的字符或单词。</li>
<li>3-gram（trigram）：三个连续的字符或单词。</li>
</ul>
</li>
<li>模型目标：基于统计分布预测某个字符或单词在一段上下文中的出现概率。</li>
</ul>
</li>
<li>
<p><strong>符号说明</strong>：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mn>1</mn><mo>:</mo><mi>N</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(C_{1:N})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 表示一段长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 的字符序列的概率分布。例如：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>’t’, ’h’, ’e’</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>0.027</mn></mrow><annotation encoding="application/x-tex">P(\text{&#x27;t&#x27;, &#x27;h&#x27;, &#x27;e&#x27;}) = 0.027</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">’t’, ’h’, ’e’</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span><span class="mord">7</span></span></span></span> 表示字符序列 “the” 出现的概率为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.027</mn></mrow><annotation encoding="application/x-tex">0.027</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span><span class="mord">7</span></span></span></span>。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>’z’, ’g’, ’q’</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>0.00000002</mn></mrow><annotation encoding="application/x-tex">P(\text{&#x27;z&#x27;, &#x27;g&#x27;, &#x27;q&#x27;}) = 0.00000002</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">’z’, ’g’, ’q’</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">2</span></span></span></span> 表示字符序列 “zgq” 几乎不可能出现。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig12-"><a class="markdownIt-Anchor" href="#-swig12-"></a> 🪐<u>N-gram模型的运作机制</u></h4>
<ol>
<li>
<p><strong>基于Markov假设</strong>：</p>
<ul>
<li>Markov链假设：序列中某个字符的概率只依赖于其前 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 个字符。</li>
<li>例如，对于三元模型（trigram），假设当前字符 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的概率只与前两个字符 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mrow><mi>i</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">c_{i-2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">c_{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 有关：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>c</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>≈</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>c</mi><mrow><mi>i</mi><mo>−</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><msub><mi>c</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(c_i \mid c_{1:i-1}) \approx P(c_i \mid c_{i-2}, c_{i-1})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
</li>
</ul>
</li>
<li>
<p><strong>概率估计</strong>：</p>
<ul>
<li>
<p>利用大量文本数据（称为语料库，corpus）统计不同字符序列的出现次数来估计概率。</p>
</li>
<li>
<p>例如，计算字符 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>e</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">&#x27;e&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mo>→</mo><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">&#x27;t&#x27; \rightarrow &#x27;h&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel">→</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 后出现的概率：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>’e’</mtext><mo>∣</mo><mtext>’th’</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>’the’</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>’th’</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{&#x27;e&#x27;} \mid \text{&#x27;th&#x27;}) = \frac{\text{Count}(\text{&#x27;the&#x27;})}{\text{Count}(\text{&#x27;th&#x27;})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">’e’</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">’th’</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">’th’</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">’the’</span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<ul>
<li></li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<p>📚例子：N-gram在实际中的应用</p>
<p>假设语料库中有以下文本：<code>&quot;the quick brown fox jumps over the lazy dog&quot;</code>，我们可以：</p>
<ol>
<li>
<p>使用2-gram（bigram）模型生成字符序列：</p>
<ul>
<li>“th” 的概率是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>’th’</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>’t’</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\text{Count}(\text{&#x27;th&#x27;})}{\text{Count}(\text{&#x27;t&#x27;})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Count</span></span><span class="mopen mtight">(</span><span class="mord text mtight"><span class="mord mtight">’t’</span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Count</span></span><span class="mopen mtight">(</span><span class="mord text mtight"><span class="mord mtight">’th’</span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
<li>“he” 的概率是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>’he’</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>’h’</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\text{Count}(\text{&#x27;he&#x27;})}{\text{Count}(\text{&#x27;h&#x27;})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Count</span></span><span class="mopen mtight">(</span><span class="mord text mtight"><span class="mord mtight">’h’</span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Count</span></span><span class="mopen mtight">(</span><span class="mord text mtight"><span class="mord mtight">’he’</span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
</ul>
</li>
<li>
<p>利用这些概率生成新文本，或为现有文本分配概率。</p>
</li>
</ol>
<hr />
<h4 id="-swig13-"><a class="markdownIt-Anchor" href="#-swig13-"></a> 🪐<u>N-gram的优点与局限性</u></h4>
<ol>
<li>
<p><strong>优点</strong>：</p>
<ul>
<li>简单易懂，基于统计的方法实现语言建模。</li>
<li>对短文本和结构化文本效果较好。</li>
</ul>
</li>
<li>
<p><strong>局限性</strong>：</p>
<ul>
<li><strong>数据稀疏性问题</strong>：某些N-gram可能在语料库中从未出现，导致概率为零。</li>
<li><strong>上下文有限性</strong>：无法捕捉长距离的依赖关系。</li>
</ul>
</li>
</ol>
<hr />
<h3 id="-swig14-"><a class="markdownIt-Anchor" href="#-swig14-"></a> ⛺<wavy>N-gram Word Models</wavy></h3>
<h4 id="-swig15-"><a class="markdownIt-Anchor" href="#-swig15-"></a> 🪐<u>什么是N-gram Word模型？</u></h4>
<ul>
<li>N-gram Word模型基于单词序列的概率分布进行语言建模。</li>
<li>核心思想是将上下文限制为某个固定数量的单词，从而简化计算复杂度。</li>
</ul>
<ol>
<li>
<p><strong>定义</strong>：</p>
<ul>
<li><strong>Bigram（2-gram）</strong>: 两个连续单词的序列，如 “please wait”, “wait for”。</li>
<li><strong>Trigram（3-gram）</strong>: 三个连续单词的序列，如 “please wait for”, “wait for your”。</li>
</ul>
</li>
<li>
<p><strong>用途</strong>：</p>
<ul>
<li>预测下一个单词的概率，给定上下文。例如：
<ul>
<li>给定 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span> = “Walden Pond’s water is so transparent that”，模型预测下一个单词 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> = “the”。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig16-"><a class="markdownIt-Anchor" href="#-swig16-"></a> 🪐<u>N-gram Word模型的概率计算</u></h4>
<ol>
<li>
<p><strong>条件概率的公式</strong>：</p>
<ul>
<li>目标是计算下一个单词的概率：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>the</mtext><mo>∣</mo><mtext>Walden Pond’s water is so transparent that</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>Walden Pond’s water is so transparent that the</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>Walden Pond’s water is so transparent that</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{the} \mid \text{Walden Pond&#x27;s water is so transparent that}) = \frac{\text{Count}(\text{Walden Pond&#x27;s water is so transparent that the})}{\text{Count}(\text{Walden Pond&#x27;s water is so transparent that})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">the</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Walden Pond’s water is so transparent that</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">Walden Pond’s water is so transparent that</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">Walden Pond’s water is so transparent that the</span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
</ul>
</li>
<li>
<p><strong>问题</strong>：</p>
<ul>
<li>长序列的上下文在语料库中可能极少出现，导致统计次数不足。</li>
</ul>
</li>
<li>
<p><strong>解决方案</strong>：</p>
<ul>
<li>使用Bigram模型，简化为计算前一个单词的条件概率：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>n</mi></msub><mo>∣</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>≈</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>n</mi></msub><mo>∣</mo><msub><mi>w</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(w_n \mid w_{1:n-1}) \approx P(w_n \mid w_{n-1})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
</li>
<li>例如：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>the</mtext><mo>∣</mo><mtext>that</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>that the</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>that</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{the} \mid \text{that}) = \frac{\text{Count}(\text{that the})}{\text{Count}(\text{that})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">the</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">that</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">that</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">that the</span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig17-"><a class="markdownIt-Anchor" href="#-swig17-"></a> 🪐<u>实际案例分析</u></h4>
<p>假设有一句话：<code>&quot;I do not like green eggs and ham&quot;</code></p>
<ol>
<li>
<p><strong>Bigram模型（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>）</strong>：</p>
<ul>
<li>目标是计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>ham</mtext><mo>∣</mo><mtext>and</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\text{ham} \mid \text{and})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">ham</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">and</span></span><span class="mclose">)</span></span></span></span>：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>ham</mtext><mo>∣</mo><mtext>and</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>and ham</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>and</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{ham} \mid \text{and}) = \frac{\text{Count}(\text{and ham})}{\text{Count}(\text{and})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">ham</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">and</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">and</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">and ham</span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
</ul>
</li>
<li>
<p><strong>Trigram模型（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">n = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>）</strong>：</p>
<ul>
<li>目标是计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>ham</mtext><mo>∣</mo><mtext>eggs and</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\text{ham} \mid \text{eggs and})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">ham</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">eggs and</span></span><span class="mclose">)</span></span></span></span>：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>ham</mtext><mo>∣</mo><mtext>eggs and</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>eggs and ham</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><mtext>eggs and</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{ham} \mid \text{eggs and}) = \frac{\text{Count}(\text{eggs and ham})}{\text{Count}(\text{eggs and})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">ham</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">eggs and</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">eggs and</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">eggs and ham</span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig18-"><a class="markdownIt-Anchor" href="#-swig18-"></a> 🪐<u>N-gram Word模型的优缺点</u></h4>
<ol>
<li>
<p><strong>优点</strong>：</p>
<ul>
<li>简单且易于实现。</li>
<li>在小规模语料库中表现良好。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong>：</p>
<ul>
<li><strong>数据稀疏性</strong>：某些N-gram组合可能在语料库中未出现，导致概率为零。</li>
<li><strong>长距离依赖问题</strong>：无法捕获远距离单词之间的依赖关系。</li>
</ul>
</li>
</ol>
<hr />
<h3 id="-swig19-"><a class="markdownIt-Anchor" href="#-swig19-"></a> ⛺<wavy>N-gram Word Models: Vocabulary and Applications</wavy></h3>
<h4 id="-swig20-"><a class="markdownIt-Anchor" href="#-swig20-"></a> 🪐<u>N-gram Word模型的挑战</u></h4>
<ol>
<li>
<p><strong>词汇量（Vocabulary）</strong>：</p>
<ul>
<li>与字符模型相比，单词模型需要处理的词汇量大得多：
<ul>
<li><strong>字符模型</strong>：语言中通常只有大约 100 个左右的唯一字符。</li>
<li><strong>单词模型</strong>：需要处理数万到数百万的单词。</li>
</ul>
</li>
<li><strong>问题</strong>：
<ul>
<li>什么才算是一个单词？例如，“U.S.” 是一个单词还是三个字符？</li>
<li>不同语言或文本格式可能有不同的单词边界（word boundaries）。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>超出词汇表的单词（Out-of-Vocabulary Words, OOV）</strong>：</p>
<ul>
<li>模型可能遇到训练语料库中未出现的新单词。</li>
<li>解决方法：引入占位符 <code>&lt;UNK&gt;</code>，用来表示任何未知单词。</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig21-"><a class="markdownIt-Anchor" href="#-swig21-"></a> 🪐<u>处理OOV单词的机制</u></h4>
<ol>
<li>
<p><strong>显式建模</strong>：</p>
<ul>
<li>在训练语料库中，将第一次出现的未知单词替换为 <code>&lt;UNK&gt;</code>。</li>
<li>对 <code>&lt;UNK&gt;</code> 进行统计，计算它的出现频率和与其他单词的关系。</li>
</ul>
</li>
<li>
<p><strong>Fallback机制</strong>：</p>
<ul>
<li>在测试语料库中，任何未见过的单词都会被映射到 <code>&lt;UNK&gt;</code>。</li>
<li>这样，模型可以基于 <code>&lt;UNK&gt;</code> 的概率分布继续工作，而不会因为未见过的单词而失败。</li>
</ul>
</li>
</ol>
<hr />
<h4 id="-swig22-"><a class="markdownIt-Anchor" href="#-swig22-"></a> 🪐<u>N-gram模型的应用</u></h4>
<p>N-gram模型的简单性和高效性使其被广泛应用于以下领域：</p>
<ol>
<li>
<p><strong>语言识别（Language Identification）</strong>：</p>
<ul>
<li>给定一段文本，识别它属于哪种自然语言（如英语、中文）。</li>
<li>例如，通过分析字符或单词序列的分布来区分法语和西班牙语。</li>
</ul>
</li>
<li>
<p><strong>拼写检查与纠正（Spelling Correction）</strong>：</p>
<ul>
<li>根据上下文预测最可能的字符或单词序列。</li>
<li>例如，将 “hte” 自动更正为 “the”。</li>
</ul>
</li>
<li>
<p><strong>文体分类（Genre Classification）</strong>：</p>
<ul>
<li>判断文本是新闻、科学论文还是推文。</li>
<li>根据N-gram分布特征，区分不同的写作风格。</li>
</ul>
</li>
<li>
<p><strong>命名实体识别（Named Entity Recognition, NER）</strong>：</p>
<img src="https://github.com/pennyzhao1507288/img_store/raw/main/24011%20intro%20AI/week9/week9_7.png" alt="Image" style="zoom:70%;" />
<ul>
<li>从文本中识别专有名词，如人名、地名或组织名。</li>
<li>例如，从一段描述化学成分的文本中提取特定化学名称。</li>
</ul>
</li>
</ol>
<p>以上文档的pdf可以用以下链接下载：<br />
<a target="_blank" rel="noopener" href="https://github.com/pennyzhao1507288/img_store/raw/main/24011%20intro%20AI/week9/Natural%20Language%20Processing_%20Language%20Models.pdf" class="download-button" download><br />
<i class="fas fa-download"></i> 下载文档<br />
</a></p>
<div class="progress"><div class="progress-bar-animated progress-bar progress-bar-striped bg-red"  style="width: 100%" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"><p>观看结束，感谢观看</p></div></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://pennyzhao1507288.github.io">Penny Zhao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://pennyzhao1507288.github.io/posts/c5806683/">https://pennyzhao1507288.github.io/posts/c5806683/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://pennyzhao1507288.github.io" target="_blank">We are the Champions</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post-share"><div class="social-share" data-image="/cover_image/24011_week9_cover2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/8bb6a0/" title="NLP_ Information-seeking Tasks"><img class="cover" src="/cover_image/24011_week9_cover3.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">NLP_ Information-seeking Tasks</div></div><div class="info-2"><div class="info-item-1"> 🏂Computer version 开始观看  🥕 NLP_ Information-seeking Tasks  ⛺Text Classification Text Classification是NLP中一个重要的任务，其目标是将一段文本分配到预定义的类别中。例如：  语言识别：判断一段文本是英语、中文还是其他语言。 流派分类：将一本书或电影的描述归为科幻、喜剧等类别。 垃圾邮件检测：判断一封邮件是“垃圾邮件（spam）”还是“正常邮件（ham）”。  📚示例：  垃圾邮件（Spam）的特点：  包含大量广告词汇，如“buy now”，“discount”。 通常会使用不规范的字符混淆，例如“ViagraFr$1.85”。   正常邮件（Ham）的特点：  语言自然，没有明显的广告倾向。    你可以将垃圾邮件分类类比为一个超市工作人员检查货物是否损坏。垃圾邮件类似有瑕疵的货物，正常邮件则是可以直接上架的商品。   ⛺Pre-processing...</div></div></div></a><a class="pagination-related" href="/posts/53c7e058/" title="Natural Language for Communication"><img class="cover" src="/cover_image/24011_week9_cover1.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Natural Language for Communication</div></div><div class="info-2"><div class="info-item-1"> 🏂Computer Version 开始观看  🥕 Natural Language for Communication  ⛺Capacity to Process Natural Language 为什么处理自然语言（Natural Language Processing, NLP）的能力重要？  获取信息（Acquire information）：NLP使计算机能够从书面语言中提取信息。例如，你可以通过搜索引擎获取论文的核心信息，也可以用智能助手如Siri从互联网查询天气信息。 与人类交流（Communicate with humans）：让计算机能够通过自然语言与人类交流，例如聊天机器人能够用普通的对话方式回答你的问题，这在客服和教育领域尤其有用。   为了实现自然语言的深度理解，需要用到以下语法模型（Grammatical models）：  词汇类别（Lexical...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/67e70231/" title="Introduction to AI-Visual Odometry"><img class="cover" src="/AI/week7_cover2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-11</div><div class="info-item-2">Introduction to AI-Visual Odometry</div></div><div class="info-2"><div class="info-item-1"> Computer Vision 开始观看  Visual Odometry  什么是Visual Odometry Visual Odometry (VO) （视觉里程计）是一种技术，通过摄像头捕捉的图像来推测机器人的位置和方向。这个过程有点像我们走路时观察周围的物体来判断自己在移动的方向和距离。  为什么要用Visual Odometry？ 在自动导航中，我们希望机器人能知道自己在环境中的位置和方向。比如一辆自动驾驶汽车需要实时了解自己在马路上的位置，以避免偏离车道或撞上其他车辆。  Wheel Odometry 是通过轮子的转动来估算位置。  Wheel odometry 然而，Wheel Odometry 有很多限制，比如它容易受到地形影响（泥泞地面、打滑的地方）。 而 Visual Odometry 则利用摄像头的视觉信息，能够在这些不平稳的环境下更精确地估算位置。  Visual Odometry的工作原理 VO...</div></div></div></a><a class="pagination-related" href="/posts/8b3ac367/" title="Introduction to AI-Feature Detection and Matching"><img class="cover" src="/AI/week7_cover.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-09</div><div class="info-item-2">Introduction to AI-Feature Detection and Matching</div></div><div class="info-2"><div class="info-item-1"> Computer version 开始观看  Feature Detection and Matching 我们讲解这个Feature Detection and Matching概念的之前可以先介绍一下Computer version。  视觉传感器 视觉传感器是能够捕获视觉数据的设备，用于帮助人工智能系统观察并理解周围环境。视觉传感器会生成丰富的视觉观测数据，供AI进行分析，最终帮助其做出决策。AI在使用视觉传感器时，通常需要关注以下几个关键过程：     特征检测 (Feature Detection)：  特征检测是从传感器观察中提取关键信息的过程，比如检测图像中的边缘、角点或斑块。 这些特征可以用作后续识别和匹配的基础，帮助系统识别环境中的对象和场景。    识别 (Recognition)：  识别是给检测到的图像特征贴上标签的过程，使系统能够区分不同的对象，比如猫、狗、建筑物等。 这个过程可以帮助AI识别物体的类别和属性，从而做出更准确的决策。    重建...</div></div></div></a><a class="pagination-related" href="/posts/75068695/" title="Robotics"><img class="cover" src="/cover_image/24011_week8_cover.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">Robotics</div></div><div class="info-2"><div class="info-item-1"> 🏂Computer version  🥕 Robotics 开始观看  ⛺什么是机器人 (Robots)? 机器人是可以执行任务的物理代理 (agent)，它们通过 导航 或 操作物理环境 来完成任务。  组成部分：  Sensors (传感器)：帮助机器人感知环境。 Effectors (执行器)：使机器人能够对环境施加物理作用。 Agent (代理)：指代机器人本身。   🪐传感器 (Sensors) 传感器是机器人的“眼睛”和“耳朵”，让机器人能感知周围环境的信息。 📝例子：  红外传感器：检测障碍物。 相机：捕捉图像。 陀螺仪：感知方向和姿态。  假设机器人通过传感器获取环境信息 sss，例如距离 ddd，传感器通过公式 s=f(e)s = f(e)s=f(e) 转化环境信息 eee 为数字信号。比如，超声波传感器通过计算声波返回的时间 ttt 来得出距离： d=vt2d = \frac{vt}{2} d=2vt​ 其中 vvv 是声速。   🪐执行器...</div></div></div></a><a class="pagination-related" href="/posts/8bb6a0/" title="NLP_ Information-seeking Tasks"><img class="cover" src="/cover_image/24011_week9_cover3.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-25</div><div class="info-item-2">NLP_ Information-seeking Tasks</div></div><div class="info-2"><div class="info-item-1"> 🏂Computer version 开始观看  🥕 NLP_ Information-seeking Tasks  ⛺Text Classification Text Classification是NLP中一个重要的任务，其目标是将一段文本分配到预定义的类别中。例如：  语言识别：判断一段文本是英语、中文还是其他语言。 流派分类：将一本书或电影的描述归为科幻、喜剧等类别。 垃圾邮件检测：判断一封邮件是“垃圾邮件（spam）”还是“正常邮件（ham）”。  📚示例：  垃圾邮件（Spam）的特点：  包含大量广告词汇，如“buy now”，“discount”。 通常会使用不规范的字符混淆，例如“ViagraFr$1.85”。   正常邮件（Ham）的特点：  语言自然，没有明显的广告倾向。    你可以将垃圾邮件分类类比为一个超市工作人员检查货物是否损坏。垃圾邮件类似有瑕疵的货物，正常邮件则是可以直接上架的商品。   ⛺Pre-processing...</div></div></div></a><a class="pagination-related" href="/posts/53c7e058/" title="Natural Language for Communication"><img class="cover" src="/cover_image/24011_week9_cover1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-25</div><div class="info-item-2">Natural Language for Communication</div></div><div class="info-2"><div class="info-item-1"> 🏂Computer Version 开始观看  🥕 Natural Language for Communication  ⛺Capacity to Process Natural Language 为什么处理自然语言（Natural Language Processing, NLP）的能力重要？  获取信息（Acquire information）：NLP使计算机能够从书面语言中提取信息。例如，你可以通过搜索引擎获取论文的核心信息，也可以用智能助手如Siri从互联网查询天气信息。 与人类交流（Communicate with humans）：让计算机能够通过自然语言与人类交流，例如聊天机器人能够用普通的对话方式回答你的问题，这在客服和教育领域尤其有用。   为了实现自然语言的深度理解，需要用到以下语法模型（Grammatical models）：  词汇类别（Lexical...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/profile.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Penny Zhao</div><div class="author-info-description">愿世间美好与你环环相扣</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/m0_69003698" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="mailto:zhaopeiyu150728899@163.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">你好，有需要可以关注公众号：画皮述说馆</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#-swig0-"><span class="toc-number">1.</span> <span class="toc-text"> 🏂Computer version</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#-swig2-"><span class="toc-number">1.1.</span> <span class="toc-text"> 🥕 Natural Language Processing Language Models</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#-swig3-"><span class="toc-number">1.1.1.</span> <span class="toc-text"> ⛺自然语言处理（NLP）与语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig4-"><span class="toc-number">1.1.1.1.</span> <span class="toc-text"> 🪐处理自然语言的能力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig5-"><span class="toc-number">1.1.1.2.</span> <span class="toc-text"> 🪐通过NLP实现知识获取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig6-"><span class="toc-number">1.1.1.3.</span> <span class="toc-text"> 🪐语言模型的作用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig7-"><span class="toc-number">1.1.1.4.</span> <span class="toc-text"> 🪐语言的特性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig8-"><span class="toc-number">1.1.1.5.</span> <span class="toc-text"> 🪐语言模型的概率分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig9-"><span class="toc-number">1.1.1.6.</span> <span class="toc-text"> 🪐自然语言的复杂性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#-swig10-"><span class="toc-number">1.1.2.</span> <span class="toc-text"> ⛺N-gram Character Models</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig11-"><span class="toc-number">1.1.2.1.</span> <span class="toc-text"> 🪐什么是N-gram模型？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig12-"><span class="toc-number">1.1.2.2.</span> <span class="toc-text"> 🪐N-gram模型的运作机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig13-"><span class="toc-number">1.1.2.3.</span> <span class="toc-text"> 🪐N-gram的优点与局限性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#-swig14-"><span class="toc-number">1.1.3.</span> <span class="toc-text"> ⛺N-gram Word Models</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig15-"><span class="toc-number">1.1.3.1.</span> <span class="toc-text"> 🪐什么是N-gram Word模型？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig16-"><span class="toc-number">1.1.3.2.</span> <span class="toc-text"> 🪐N-gram Word模型的概率计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig17-"><span class="toc-number">1.1.3.3.</span> <span class="toc-text"> 🪐实际案例分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig18-"><span class="toc-number">1.1.3.4.</span> <span class="toc-text"> 🪐N-gram Word模型的优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#-swig19-"><span class="toc-number">1.1.4.</span> <span class="toc-text"> ⛺N-gram Word Models: Vocabulary and Applications</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig20-"><span class="toc-number">1.1.4.1.</span> <span class="toc-text"> 🪐N-gram Word模型的挑战</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig21-"><span class="toc-number">1.1.4.2.</span> <span class="toc-text"> 🪐处理OOV单词的机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-swig22-"><span class="toc-number">1.1.4.3.</span> <span class="toc-text"> 🪐N-gram模型的应用</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/84b720fa/" title="intro to finance"><img src="/cover_image/39032_week1_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="intro to finance"/></a><div class="content"><a class="title" href="/posts/84b720fa/" title="intro to finance">intro to finance</a><time datetime="2025-01-28T10:44:42.000Z" title="发表于 2025-01-28 18:44:42">2025-01-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/ecfd70f5/" title="Time series(1)"><img src="/cover_image/38032_week1_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Time series(1)"/></a><div class="content"><a class="title" href="/posts/ecfd70f5/" title="Time series(1)">Time series(1)</a><time datetime="2025-01-25T01:28:05.000Z" title="发表于 2025-01-25 09:28:05">2025-01-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8bb6a0/" title="NLP_ Information-seeking Tasks"><img src="/cover_image/24011_week9_cover3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="NLP_ Information-seeking Tasks"/></a><div class="content"><a class="title" href="/posts/8bb6a0/" title="NLP_ Information-seeking Tasks">NLP_ Information-seeking Tasks</a><time datetime="2024-11-24T22:23:23.000Z" title="发表于 2024-11-25 06:23:23">2024-11-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/c5806683/" title="Natural Language Processing Language Models"><img src="/cover_image/24011_week9_cover2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Natural Language Processing Language Models"/></a><div class="content"><a class="title" href="/posts/c5806683/" title="Natural Language Processing Language Models">Natural Language Processing Language Models</a><time datetime="2024-11-24T22:17:19.000Z" title="发表于 2024-11-25 06:17:19">2024-11-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/53c7e058/" title="Natural Language for Communication"><img src="/cover_image/24011_week9_cover1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Natural Language for Communication"/></a><div class="content"><a class="title" href="/posts/53c7e058/" title="Natural Language for Communication">Natural Language for Communication</a><time datetime="2024-11-24T22:00:14.000Z" title="发表于 2024-11-25 06:00:14">2024-11-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Penny Zhao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.isShuoshuo
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'pennyzhao1507288/pennyzhao1507288.github.io',
      'data-repo-id': 'R_kgDONMjCuQ',
      'data-category-id': 'DIC_kwDONMjCuc4CkIEb',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !true) {
    if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>